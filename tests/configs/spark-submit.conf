projectdir="""C:\Users\DmVIvakin\PycharmProjects\ssh-spark-submit\tests"""

ssh = {
  host = "hdp3-client.dmp.vimpelcom.ru"
  user = "DmVIvakin"
  key = """C:\Users\DmVIvakin\.ssh\id_dmp"""
  workdir = "/home/dmvivakin/mayak"

  env = [
    "SPARK_MAJOR_VERSION=3",
  ]

  beforeScript = [
    "echo $SPARK_MAJOR_VERSION"
  ]

  afterScript = [
    "echo $SPARK_MAJOR_VERSION",
    "echo $APPID",
    "rm -r -f /home/dmvivakin/mayak/logs.txt",
    "yarn logs -applicationId $APPID -out /home/dmvivakin/mayak/logs.txt",
  ]
}

application = {
  class = ru.beeline.dmp.dpi.garda.consumer.GardaConsumer
  name = My tested application
  args = [
    "--event-date",
    "2024-09-01T10:00:00+0300"
  ]
}

spark = {
  master = yarn
  deployMode = cluster
  driverCores = 2
  driverMemory = "512m"
  executorMemory = "512m"
  numExecutors = 2
  executorCores = 2
  verbose = true

//  principal = "I'am"
//  keytab = "/path/to/my.keytab"

//  totalExecutorCores=10
//  urls=[
//    "host1:port",
//    "host1:port",
//  ]
//  supervise=true

//  maxFailures  = 2
//  numWorkers  = 2


  configs = [
    """spark.yarn.report.interval=30000"""
    """spark.executor.extraJavaOptions="-Djava.security.auth.login.config=./jaas.conf -Dconfig.file=./application.conf -Dlog4jspark.root.logger=INFO,console"""",
    """spark.driver.extraJavaOptions="-Djava.security.auth.login.config=./jaas.conf -Dconfig.file=./application.conf -Dlog4jspark.root.logger=INFO,console -Dfile.encoding=utf-8 -Dlog4j.debug=false"""",
    """spark.executor.extraJavaOptions="-Dconfig.file=./application.conf"""",
    """spark.driver.extraJavaOptions="-Dconfig.file=./application.conf"""",
  ]


  files = [
    """configs/application.conf""",
    """configs/jaas.conf""",
  ]

  jars = [
    """configs/spark-sql-kafka-0-10_2.12-3.0.1.jar""",
    """configs/spark-streaming-kafka-0-10_2.12-3.0.1.jar""",
    """configs/spark-avro_2.12-3.0.1.jar""",
  ]

  packages = []
  repositories = []
  py-files = []

}